{
 "metadata": {
  "signature": "sha256:6202c910fd49e58e824ca799d2b6f988ca85a6aab007bbad5b38a202c069cde7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from sklearn.utils import shuffle\n",
      "import matplotlib\n",
      "matplotlib.use('Agg')\n",
      "import matplotlib.pyplot as plt\n",
      "import os\n",
      "\n",
      "from keras.models import Sequential, Model\n",
      "from keras.layers import Dense, Input\n",
      "from keras.layers import Reshape\n",
      "\n",
      "from keras.layers.core import Activation\n",
      "from keras.layers.normalization import BatchNormalization\n",
      "from keras.layers.convolutional import UpSampling2D\n",
      "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
      "from keras.layers.advanced_activations import LeakyReLU\n",
      "\n",
      "from keras.callbacks import EarlyStopping\n",
      "from keras.layers.core import Flatten\n",
      "from keras.optimizers import SGD, Adam\n",
      "from keras.datasets import mnist\n",
      "from keras.utils import np_utils, plot_model\n",
      "#from keras import initializations"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Using TensorFlow backend.\n",
        "Couldn't import dot_parser, loading of dot files will not be possible."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def dataInit():\n",
      "\tprint('Loading the data')\n",
      "\t(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
      "\tX_train = np.concatenate((X_train, X_test), axis=0)\n",
      "\tX_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
      "\tprint('Training Data: ', X_train.shape)\n",
      "\tnpRandom = np.random.RandomState() # Container for the Mersenne Twister pseudo-random number generator\n",
      "\tX_noise = []\n",
      "\tfor i in range(X_train.shape[0]):\n",
      "\t\trandomNoise = npRandom.uniform(-1,1,100)\n",
      "\t\tX_noise.append(randomNoise)\n",
      "\tX_noise = np.array(X_noise)\n",
      "\tprint('Random Noise Data: ', X_noise.shape)\n",
      "\treturn X_train, X_noise\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def saveImage(imageData, imageName, epoch):\n",
      "\tf, ax = plt.subplots(16, 8)\n",
      "\tk = 0\n",
      "\tfor i in range(16):\n",
      "\t\tfor j in range(8):\n",
      "\t\t\tpltImage = imageData[k][0]\n",
      "\t\t\tax[i,j].imshow(pltImage, interpolation='nearest',cmap='gray_r')\n",
      "\t\t\tax[i,j].axis('off')\n",
      "\t\t\tk = k+1\n",
      "\tf.set_size_inches(18.5, 10.5)\n",
      "\tf.savefig('images/'+imageName+'_after_'+str(epoch)+'_epoch.png', dpi = 100, bbox_inches='tight', pad_inches = 0)\n",
      "\tplt.close(f)\n",
      "\treturn None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if __name__ == '__main__':\n",
      "\n",
      "\tbatchSize = 128\n",
      "\tnbEpoch = 1\n",
      "\tdecayIter = 100\n",
      "\tlr = 0.0002\n",
      "\n",
      "\tX_train, X_noise = dataInit()\n",
      "\tprint(X_train.shape)\n",
      "\tX_train = X_train[:, np.newaxis, :, :] #Each newaxis object in the selection tuple serves to expand the dimensions of the resulting selection by one unit-length dimension\n",
      "\tnumExamples = (X_train.shape)[0]\n",
      "\tnumBatches = int(numExamples/float(batchSize))\n",
      "\n",
      "\tprint('Number of examples: ', numExamples)\n",
      "\tprint('Number of Batches: ', numBatches)\n",
      "\tprint('Number of epochs: ', nbEpoch)\n",
      "\n",
      "\tadam=Adam(lr=lr, beta_1=0.5) #lr=0.001 too high, and unstable.\n",
      "\n",
      "\tprint('Generator Model')\n",
      "\n",
      "\tgenerator = Sequential() # The Sequential model is a linear stack of layers. https://keras.io/getting-started/sequential-model-guide/\n",
      "\tgenerator.add(Dense( input_dim=100, output_dim=(128*7*7)))\n",
      "\tgenerator.add(Activation('relu'))\n",
      "\tgenerator.add(Reshape((128, 7, 7)))\n",
      "    \n",
      "\tgenerator.add(UpSampling2D(size=(2, 2)))\n",
      "\tgenerator.add(Convolution2D(64, 5, 5, border_mode='same'))\n",
      "\tgenerator.add(Activation('relu'))\n",
      "\tgenerator.add(UpSampling2D(size=(2, 2)))\n",
      "\tgenerator.add(Convolution2D(1, 5, 5, border_mode='same'))\n",
      "\tgenerator.add(Activation('tanh'))\n",
      "\tgenerator.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
      "    \n",
      "\tplot_model(generator,to_file='model.png')\n",
      "\tfrom IPython.display import display\n",
      "\tdisplay(\"model.png\")\n",
      "    \n",
      "\t![alt text](model.png \"Title\")\n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading the data\n",
        "('Training Data: ', (70000, 28, 28))"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Random Noise Data: ', (70000, 100))"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:23: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=6272, input_dim=100)`\n",
        "-c:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5), padding=\"same\")`\n",
        "-c:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1, (5, 5), padding=\"same\")`\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(70000, 28, 28)\n",
        "('Number of examples: ', 70000)\n",
        "('Number of Batches: ', 546)\n",
        "('Number of epochs: ', 1)\n",
        "Generator Model\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "'model.png'"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/bin/sh: 1: Syntax error: \"(\" unexpected\r\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\tprint('Discriminator Model')\n",
      "\tdiscriminator = Sequential()\n",
      "\tdiscriminator.add(Convolution2D(64, 5, 5, border_mode='same', subsample=(2,2), input_shape=(1,28,28))) #initialization \n",
      "\tdiscriminator.add(LeakyReLU(0.2))\n",
      "\tdiscriminator.add(Convolution2D(128, 5, 5, border_mode='same', subsample=(2,2)))\n",
      "\tdiscriminator.add(LeakyReLU(0.2))\n",
      "\tdiscriminator.add(Flatten())\n",
      "\tdiscriminator.add(Dense(1))\n",
      "\tdiscriminator.add(Activation('sigmoid'))\n",
      "\tdiscriminator.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
      "\tprint(discriminator.summary())\n",
      "\tdiscriminator.trainable = False"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Discriminator Model\n",
        "_________________________________________________________________"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Layer (type)                 Output Shape              Param #   \n",
        "=================================================================\n",
        "conv2d_3 (Conv2D)            (None, 64, 14, 14)        1664      \n",
        "_________________________________________________________________\n",
        "leaky_re_lu_1 (LeakyReLU)    (None, 64, 14, 14)        0         \n",
        "_________________________________________________________________\n",
        "conv2d_4 (Conv2D)            (None, 128, 7, 7)         204928    \n",
        "_________________________________________________________________\n",
        "leaky_re_lu_2 (LeakyReLU)    (None, 128, 7, 7)         0         \n",
        "_________________________________________________________________\n",
        "flatten_1 (Flatten)          (None, 6272)              0         \n",
        "_________________________________________________________________\n",
        "dense_2 (Dense)              (None, 1)                 6273      \n",
        "_________________________________________________________________\n",
        "activation_4 (Activation)    (None, 1)                 0         \n",
        "=================================================================\n",
        "Total params: 212,865\n",
        "Trainable params: 212,865\n",
        "Non-trainable params: 0\n",
        "_________________________________________________________________\n",
        "None\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5), padding=\"same\", strides=(2, 2), input_shape=(1, 28, 28...)`\n",
        "-c:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (5, 5), padding=\"same\", strides=(2, 2))`\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\tprint('DCGAN model')\n",
      "\n",
      "\tdcganInput = Input(shape=(100,))\n",
      "\tx = generator(dcganInput)\n",
      "\tdcganOutput = discriminator(x)\n",
      "\tdcgan = Model(input=dcganInput, output=dcganOutput)\n",
      "\tdcgan.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
      "\n",
      "\tdiscriminator.trainable = True\n",
      "\n",
      "\tif not os.path.exists('images'):\n",
      "\t\tos.makedirs('images')\n",
      "\tif not os.path.exists('models'):\n",
      "\t\tos.makedirs('models')\n",
      "\tif not os.path.exists('metrics'):\n",
      "\t\tos.makedirs('metrics')\n",
      "\n",
      "\tdLoss = []\n",
      "\tgLoss = []\n",
      "\n",
      "\tfor epoch in range(1, nbEpoch + 1):\n",
      "\t\tprint('Epoch: ', epoch)\n",
      "\n",
      "\t\tfor i in range(numBatches):\n",
      "            \n",
      "\t\t\tnoisePredictBatch = X_noise[np.random.randint(numExamples, size = batchSize)]\n",
      "\t\t\tnoiseDataBatch = generator.predict(noisePredictBatch)\n",
      "\n",
      "\t\t\torigDataBatch = X_train[np.random.randint(numExamples, size = batchSize)]\n",
      "\t\t\tnoiseLabelsBatch, origLabelsBatch = np.zeros(batchSize).astype(int), np.ones(batchSize).astype(int)\n",
      "\n",
      "\t\t\ttrainBatch = np.concatenate((noiseDataBatch, origDataBatch), axis = 0)\n",
      "\t\t\ttrainLabels = np.concatenate((noiseLabelsBatch, origLabelsBatch))\n",
      "\t\t\ttrainBatch, trainLabels = shuffle(trainBatch, trainLabels)\n",
      "\n",
      "\t\t\tdiscriminatorLoss = discriminator.train_on_batch(trainBatch, trainLabels)#sequential model API\n",
      "            #labeling for generator training\n",
      "\t\t\tdcganLabels = np.ones(batchSize).astype(int)\n",
      "\t\t\tdiscriminator.trainable = False\n",
      "\t\t\tdcganLoss = dcgan.train_on_batch(noisePredictBatch, dcganLabels)\n",
      "\t\t\tdiscriminator.trainable = True\n",
      "\n",
      "\t\tdLoss.append(discriminatorLoss)\n",
      "\t\tgLoss.append(dcganLoss)\n",
      "\t\t\n",
      "\t\tif (epoch % 5 == 0) or (epoch == 1):\n",
      "\t\t\tsaveImage(noiseDataBatch, 'generated', epoch)\n",
      "\t\t\tprint('after epoch: ', epoch)\n",
      "\t\t\tprint ('dcgan Loss: ', dcganLoss, '\\t discriminator loss', discriminatorLoss)\n",
      "\t\t\tgenerator.save('models/generator_'+str(epoch)+'.h5')\n",
      "\n",
      "\t\tif epoch > decayIter :\n",
      "\t\t\tlrD = discriminator.optimizer.lr.get_value()\n",
      "\t\t\tlrG = generator.optimizer.lr.get_value()\n",
      "\t\t\tdiscriminator.optimizer.lr.set_value((lrD - lr/decayIter).astype(np.float32))\n",
      "\t\t\tgenerator.optimizer.lr.set_value((lrG - lr/decayIter).astype(np.float32))\n",
      "\t\t\tprint('learning rate linearly decayed')\n",
      "\n",
      "\tnp.save('metrics/dLoss.npy', np.array(dLoss))\n",
      "\tnp.save('metrics/gLoss.npy', np.array(gLoss))\n",
      "\tprint('Peace')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DCGAN model\n",
        "('Epoch: ', 1)"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}