{
 "metadata": {
  "signature": "sha256:c9c547c1a44ab06e35e223a2e319937fcfcd319a35782caf198b90ef03c8b22b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from sklearn.utils import shuffle\n",
      "import matplotlib\n",
      "matplotlib.use('Agg')# matplotlib backend\n",
      "import matplotlib.pyplot as plt\n",
      "import os\n",
      "\n",
      "from keras.models import Sequential, Model\n",
      "from keras.layers import Dense, Input\n",
      "from keras.layers import Reshape\n",
      "\n",
      "from keras.layers.core import Activation\n",
      "from keras.layers.normalization import BatchNormalization\n",
      "from keras.layers.convolutional import UpSampling2D\n",
      "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
      "from keras.layers.advanced_activations import LeakyReLU\n",
      "\n",
      "from keras.callbacks import EarlyStopping\n",
      "from keras.layers.core import Flatten\n",
      "from keras.optimizers import SGD, Adam\n",
      "from keras.datasets import mnist\n",
      "from keras.utils import np_utils, plot_model\n",
      "#from keras import initializations"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Using TensorFlow backend.\n",
        "Couldn't import dot_parser, loading of dot files will not be possible."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def dataInit():\n",
      "\tprint('Loading the data')\n",
      "\t(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
      "\tX_train = np.concatenate((X_train, X_test), axis=0)\n",
      "\tX_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
      "\tprint('Training Data: ', X_train.shape)\n",
      "\tnpRandom = np.random.RandomState() # Container for the Mersenne Twister pseudo-random number generator\n",
      "\tX_noise = []\n",
      "\tfor i in range(X_train.shape[0]):\n",
      "\t\trandomNoise = npRandom.uniform(-1,1,100)\n",
      "\t\tX_noise.append(randomNoise)\n",
      "\tX_noise = np.array(X_noise)\n",
      "\tprint('Random Noise Data: ', X_noise.shape)\n",
      "\treturn X_train, X_noise\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def saveImage(imageData, imageName, epoch):\n",
      "\tf, ax = plt.subplots(16, 8)\n",
      "\tk = 0\n",
      "\tfor i in range(16):\n",
      "\t\tfor j in range(8):\n",
      "\t\t\tpltImage = imageData[k][0]\n",
      "\t\t\tax[i,j].imshow(pltImage, interpolation='nearest',cmap='gray_r')\n",
      "\t\t\tax[i,j].axis('off')\n",
      "\t\t\tk = k+1\n",
      "\tf.set_size_inches(18.5, 10.5)\n",
      "\tf.savefig('images/'+imageName+'_after_'+str(epoch)+'_epoch.png', dpi = 100, bbox_inches='tight', pad_inches = 0)\n",
      "\tplt.close(f)\n",
      "\treturn None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if __name__ == '__main__':\n",
      "\n",
      "\tbatchSize = 128\n",
      "\tnbEpoch = 1\n",
      "\tdecayIter = 100\n",
      "\tlr = 0.0002\n",
      "\n",
      "\tX_train, X_noise = dataInit()\n",
      "\tX_train = X_train[:, np.newaxis, :, :] #Each newaxis object in the selection tuple serves to expand the dimensions of the resulting selection by one unit-length dimension\n",
      "\tnumExamples = (X_train.shape)[0]\n",
      "\tnumBatches = int(numExamples/float(batchSize))\n",
      "\n",
      "\tprint('Number of examples: ', numExamples)\n",
      "\tprint('Number of Batches: ', numBatches)\n",
      "\tprint('Number of epochs: ', nbEpoch)\n",
      "\n",
      "\tadam=Adam(lr=lr, beta_1=0.5) # lr=0.001 too high, and unstable that is changed.\n",
      "\n",
      "\tprint('Generator Model')\n",
      "\n",
      "\tgenerator = Sequential() # The Sequential model is a linear stack of layers. https://keras.io/getting-started/sequential-model-guide/\n",
      "\tgenerator.add(Dense( input_dim=100, output_dim=(128*7*7)))\n",
      "\tgenerator.add(Activation('relu'))\n",
      "\tgenerator.add(Reshape((128, 7, 7)))\n",
      "    \n",
      "\tgenerator.add(UpSampling2D(size=(2, 2)))\n",
      "    \n",
      "\tgenerator.add(Convolution2D(64, 5, 5, border_mode='same'))\n",
      "\tgenerator.add(Activation('relu'))\n",
      "    \n",
      "\tgenerator.add(UpSampling2D(size=(2, 2)))\n",
      "\tgenerator.add(Convolution2D(1, 5, 5, border_mode='same'))\n",
      "    \n",
      "\tgenerator.add(Activation('tanh'))\n",
      "\tgenerator.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
      "    \n",
      "\tplot_model(generator,to_file='model.png')\n",
      "\tfrom IPython.display import Image\n",
      "\tImage(filename=\"model.png\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading the data\n",
        "('Training Data: ', (70000, 28, 28))"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Random Noise Data: ', (70000, 100))"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:22: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=6272, input_dim=100)`\n",
        "-c:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5), padding=\"same\")`\n",
        "-c:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1, (5, 5), padding=\"same\")`\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Number of examples: ', 70000)\n",
        "('Number of Batches: ', 546)\n",
        "('Number of epochs: ', 1)\n",
        "Generator Model\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\tprint('Discriminator Model')\n",
      "\tdiscriminator = Sequential()\n",
      "\tdiscriminator.add(Convolution2D(64, 5, 5, border_mode='same', subsample=(2,2), input_shape=(1,28,28))) #initialization \n",
      "\tdiscriminator.add(LeakyReLU(0.2))\n",
      "\tdiscriminator.add(Convolution2D(128, 5, 5, border_mode='same', subsample=(2,2)))\n",
      "\tdiscriminator.add(LeakyReLU(0.2))\n",
      "\tdiscriminator.add(Flatten())\n",
      "\tdiscriminator.add(Dense(1))\n",
      "\tdiscriminator.add(Activation('sigmoid'))\n",
      "\tdiscriminator.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
      "\tprint(discriminator.summary())\n",
      "\tdiscriminator.trainable = False"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Discriminator Model\n",
        "_________________________________________________________________"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Layer (type)                 Output Shape              Param #   \n",
        "=================================================================\n",
        "conv2d_3 (Conv2D)            (None, 64, 14, 14)        1664      \n",
        "_________________________________________________________________\n",
        "leaky_re_lu_1 (LeakyReLU)    (None, 64, 14, 14)        0         \n",
        "_________________________________________________________________\n",
        "conv2d_4 (Conv2D)            (None, 128, 7, 7)         204928    \n",
        "_________________________________________________________________\n",
        "leaky_re_lu_2 (LeakyReLU)    (None, 128, 7, 7)         0         \n",
        "_________________________________________________________________\n",
        "flatten_1 (Flatten)          (None, 6272)              0         \n",
        "_________________________________________________________________\n",
        "dense_2 (Dense)              (None, 1)                 6273      \n",
        "_________________________________________________________________\n",
        "activation_4 (Activation)    (None, 1)                 0         \n",
        "=================================================================\n",
        "Total params: 212,865\n",
        "Trainable params: 212,865\n",
        "Non-trainable params: 0\n",
        "_________________________________________________________________\n",
        "None\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5), padding=\"same\", strides=(2, 2), input_shape=(1, 28, 28...)`\n",
        "-c:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (5, 5), padding=\"same\", strides=(2, 2))`\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\tprint('DCGAN model')\n",
      "\n",
      "\tdcganInput = Input(shape=(100,))\n",
      "\tx = generator(dcganInput)\n",
      "\tdcganOutput = discriminator(x)\n",
      "\tdcgan = Model(input=dcganInput, output=dcganOutput)\n",
      "\tdcgan.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
      "\n",
      "\tdiscriminator.trainable = True\n",
      "\n",
      "\tif not os.path.exists('images'):\n",
      "\t\tos.makedirs('images')\n",
      "\tif not os.path.exists('models'):\n",
      "\t\tos.makedirs('models')\n",
      "\tif not os.path.exists('metrics'):\n",
      "\t\tos.makedirs('metrics')\n",
      "\n",
      "\tdLoss = []\n",
      "\tgLoss = []\n",
      "\n",
      "\tfor epoch in range(1, nbEpoch + 1):\n",
      "\t\tprint('Epoch: ', epoch)\n",
      "\n",
      "\t\tfor i in range(numBatches):\n",
      "            \n",
      "\t\t\tnoisePredictBatch = X_noise[np.random.randint(numExamples, size = batchSize)]\n",
      "\t\t\tnoiseDataBatch = generator.predict(noisePredictBatch)\n",
      "\n",
      "\t\t\torigDataBatch = X_train[np.random.randint(numExamples, size = batchSize)]\n",
      "\t\t\tnoiseLabelsBatch, origLabelsBatch = np.zeros(batchSize).astype(int), np.ones(batchSize).astype(int)\n",
      "\n",
      "\t\t\ttrainBatch = np.concatenate((noiseDataBatch, origDataBatch), axis = 0)\n",
      "\t\t\ttrainLabels = np.concatenate((noiseLabelsBatch, origLabelsBatch))\n",
      "\t\t\ttrainBatch, trainLabels = shuffle(trainBatch, trainLabels)\n",
      "\n",
      "\t\t\tdiscriminatorLoss = discriminator.train_on_batch(trainBatch, trainLabels)#sequential model API\n",
      "            #labeling for generator training\n",
      "\t\t\tdcganLabels = np.ones(batchSize).astype(int)\n",
      "\t\t\tdiscriminator.trainable = False\n",
      "\t\t\tdcganLoss = dcgan.train_on_batch(noisePredictBatch, dcganLabels)\n",
      "\t\t\tdiscriminator.trainable = True\n",
      "\n",
      "\t\tdLoss.append(discriminatorLoss)\n",
      "\t\tgLoss.append(dcganLoss)\n",
      "\t\t\n",
      "\t\tif (epoch % 5 == 0) or (epoch == 1):\n",
      "\t\t\tsaveImage(noiseDataBatch, 'generated', epoch)\n",
      "\t\t\tprint('after epoch: ', epoch)\n",
      "\t\t\tprint ('dcgan Loss: ', dcganLoss, '\\t discriminator loss', discriminatorLoss)\n",
      "\t\t\tgenerator.save('models/generator_'+str(epoch)+'.h5')\n",
      "\n",
      "\t\tif epoch > decayIter :\n",
      "\t\t\tlrD = discriminator.optimizer.lr.get_value()\n",
      "\t\t\tlrG = generator.optimizer.lr.get_value()\n",
      "\t\t\tdiscriminator.optimizer.lr.set_value((lrD - lr/decayIter).astype(np.float32))\n",
      "\t\t\tgenerator.optimizer.lr.set_value((lrG - lr/decayIter).astype(np.float32))\n",
      "\t\t\tprint('learning rate linearly decayed')\n",
      "\n",
      "\tnp.save('metrics/dLoss.npy', np.array(dLoss))\n",
      "\tnp.save('metrics/gLoss.npy', np.array(gLoss))\n",
      "\tprint('Peace')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DCGAN model\n",
        "('Epoch: ', 1)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:6: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"se..., inputs=Tensor(\"in...)`\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-6-f43833a8e1c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mdcganLabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0mdcganLoss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdcgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisePredictBatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdcganLabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                 \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/home/sghan/.local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1837\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1838\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1839\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1840\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/home/sghan/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/home/sghan/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/home/sghan/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/home/sghan/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/home/sghan/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/home/sghan/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}